{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "020141d53f7848ad9dfefa5d97a890ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 0,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "image/*",
            "button_style": "",
            "data": [],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_afe2bd1009d64ab0ad09577fb0847558",
            "metadata": [],
            "multiple": false,
            "style": "IPY_MODEL_c40a75ea661846b8ad36e34a41b929d2"
          }
        },
        "afe2bd1009d64ab0ad09577fb0847558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40a75ea661846b8ad36e34a41b929d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q56MUQfdrHy6",
        "outputId": "50d607c1-eddf-4fdd-e437-167b5391f33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.13.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the OpenAI library to interact with the OpenAI API.\n",
        "from openai import OpenAI\n",
        "import textwrap\n",
        "import requests  # used to download images\n",
        "import os  # used to access filepaths\n",
        "from PIL import Image  # used to print and edit images\n",
        "import base64\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, Image, clear_output\n",
        "\n",
        "# Define the path to your API key file\n",
        "api_key_file = 'api_key.txt'\n",
        "\n",
        "# Read the API key from the file\n",
        "with open(api_key_file, 'r') as file:\n",
        "    api_key = file.read().strip()\n",
        "\n",
        "# Initialize the OpenAI client with your API key.\n",
        "client = OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "rXbvlDByGl1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chatbot**"
      ],
      "metadata": {
        "id": "Vm8XqWLq_SOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display the last message in the chat history.\n",
        "# It takes the chat history list as an argument.\n",
        "def display_last_message(messages):\n",
        "    # Check if the messages list is not empty to avoid index errors.\n",
        "    if messages:\n",
        "        # Retrieve the last message from the chat history.\n",
        "        last_message = messages[-1]\n",
        "        # Print the role (User or Assistant) and content of the last message.\n",
        "        print(f\"{last_message['role'].capitalize()}: {last_message['content']}\")"
      ],
      "metadata": {
        "id": "P8tX6u8AG0z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get the assistant's response using the OpenAI API.\n",
        "# It takes the chat history as an argument to maintain context in the conversation.\n",
        "def get_assistant_response(messages):\n",
        "    # Call the OpenAI API to generate a chat completion/response.\n",
        "    # The function constructs a list of messages with their roles and content,\n",
        "    # sets the conversation model to GPT-4, and configures response parameters.\n",
        "    r = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in messages],\n",
        "        temperature=0.5,  # Controls randomness. Lower values make responses more deterministic.\n",
        "        max_tokens=128,    # Maximum length of the response.\n",
        "        top_p=1           # Controls diversity. Setting to 1.0 takes the most likely next words.\n",
        "    )\n",
        "    # Extract the content of the response from the API's return object.\n",
        "    response = r.choices[0].message.content\n",
        "    # Return the response content.\n",
        "    return response"
      ],
      "metadata": {
        "id": "mmrhNDeBG4Xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the chat history with a system message describing the chatbot's character.\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "0_Z8MxDCHERt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the initial system message by calling the display_last_message function.\n",
        "display_last_message(messages)\n",
        "\n",
        "# Main loop to handle the conversation.\n",
        "while True:\n",
        "    # Prompt the user for input and append their message to the chat history.\n",
        "    user_input = input(\"User: \")\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Get the assistant's response based on the updated chat history and append it to the chat history.\n",
        "    assistant_response = get_assistant_response(messages)\n",
        "    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    # Display the last two messages (the most recent user input and the assistant's response).\n",
        "    display_last_message(messages[-2:])  # display the last exchange only.\n"
      ],
      "metadata": {
        "id": "itTyxeGDsz0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarization**"
      ],
      "metadata": {
        "id": "kCqLYd3FJyi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_content_for_second_grade():\n",
        "    print(\"Enter content to summarize for a second-grade student. Type 'exit' to return to the main menu.\")\n",
        "    while True:\n",
        "        content_to_summarize = input(\"Content: \")\n",
        "        if content_to_summarize.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": \"Summarize the content you are provided with for a second-grade student.\"\n",
        "                },\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": content_to_summarize\n",
        "                }\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=640,\n",
        "            top_p=1\n",
        "        )\n",
        "        summary = response.choices[0].message.content\n",
        "\n",
        "        wrapped_summary = textwrap.fill(summary, width=80)\n",
        "        print(\"\\nSummary for a Second-Grade Student:\\n\", wrapped_summary)"
      ],
      "metadata": {
        "id": "IZRyO5moJ25o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_content_for_second_grade()"
      ],
      "metadata": {
        "id": "mYBrr6xKRi6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image Generation**"
      ],
      "metadata": {
        "id": "cxgY-uDopkC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set a directory to save DALL·E images to\n",
        "image_dir_name = \"images\"\n",
        "image_dir = os.path.join(os.curdir, image_dir_name)\n",
        "\n",
        "# create the directory if it doesn't yet exist\n",
        "if not os.path.isdir(image_dir):\n",
        "    os.mkdir(image_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUFtep2XrBDa",
        "outputId": "bf6f604b-09f0-4a00-966e-d04648db445d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image_dir='./images'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"A cyberpunk monkey hacker dreaming of a beautiful bunch of bananas, digital art\"\n",
        "\n",
        "response = client.images.generate(\n",
        "  model=\"dall-e-3\",\n",
        "  prompt=prompt,\n",
        "  size=\"1024x1024\",\n",
        "  quality=\"standard\",\n",
        "  n=1,\n",
        ")\n",
        "\n",
        "# save the image\n",
        "generated_image_name = \"generated_image.png\"\n",
        "generated_image_filepath = os.path.join(image_dir, generated_image_name)\n",
        "generated_image_url = response.data[0].url  # extract image URL from response\n",
        "generated_image = requests.get(generated_image_url).content  # download the image\n",
        "\n",
        "with open(generated_image_filepath, \"wb\") as image_file:\n",
        "    image_file.write(generated_image)  # write the image to the file\n",
        "\n",
        "# print the image\n",
        "print(generated_image_filepath)\n",
        "display(Image.open(generated_image_filepath))\n"
      ],
      "metadata": {
        "id": "Sfs6CRxXplsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vision API**"
      ],
      "metadata": {
        "id": "9g6jYx8QsVwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image\n",
        "def encode_image(image_file):\n",
        "    return base64.b64encode(image_file).decode('utf-8')\n",
        "\n",
        "# Function to process the uploaded image, display it, and get the summary\n",
        "def process_image_and_get_summary(change):\n",
        "    clear_output(wait=True)  # Clear the previous output including the file upload button\n",
        "    uploader = change.owner\n",
        "    if uploader.value:\n",
        "        # Get the uploaded file; uploader.value is a dict with file names as keys\n",
        "        uploaded_file = next(iter(uploader.value.values()))\n",
        "        file_content = uploaded_file['content']\n",
        "\n",
        "        # Display the uploader again for new uploads\n",
        "        display(uploader)\n",
        "\n",
        "        # Display the uploaded image\n",
        "        display(Image(data=file_content))\n",
        "\n",
        "        # Encode the uploaded image\n",
        "        base64_image = encode_image(file_content)\n",
        "\n",
        "        headers = {\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"Authorization\": f\"Bearer {api_key}\"\n",
        "        }\n",
        "\n",
        "        payload = {\n",
        "            \"model\": \"gpt-4-vision-preview\",\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": \"What’s in this image?\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
        "                            }\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            \"max_tokens\": 300\n",
        "        }\n",
        "\n",
        "        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            json_data = response.json()\n",
        "            summary = json_data['choices'][0]['message']['content']\n",
        "            wrapped_summary = textwrap.fill(summary, width=80)\n",
        "            print(wrapped_summary)\n",
        "        else:\n",
        "            print(f\"Failed to get response: {response.status_code}\")\n",
        "        # Prepare for the next upload\n",
        "        uploader.value.clear()\n",
        "        uploader._counter = 0\n",
        "    else:\n",
        "        print(\"No file uploaded.\")\n"
      ],
      "metadata": {
        "id": "9FMgs3GCsXYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a file upload button\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='image/*',  # Accept images only\n",
        "    multiple=False  # Allow single file upload\n",
        ")\n",
        "\n",
        "display(uploader)\n",
        "\n",
        "# Attach the observe method to the uploader so it automatically calls the specified function\n",
        "# when a file is uploaded.\n",
        "uploader.observe(process_image_and_get_summary, names='value')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "020141d53f7848ad9dfefa5d97a890ca",
            "afe2bd1009d64ab0ad09577fb0847558",
            "c40a75ea661846b8ad36e34a41b929d2"
          ]
        },
        "id": "iRAuN5no-0en",
        "outputId": "d4c80645-addb-4288-8856-f585441e8fe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='image/*', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "020141d53f7848ad9dfefa5d97a890ca"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}